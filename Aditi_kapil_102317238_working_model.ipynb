{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a91f33",
   "metadata": {},
   "source": [
    "# Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad18f1",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aff4e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675ffcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print(\"Loading and preprocessing data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5cc16",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "Training KNN...\n",
      "Training SVM...\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "train_data = pd.read_csv('emnist-digits-train.csv')\n",
    "test_data = pd.read_csv('emnist-digits-test.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_data.iloc[:, 1:].values\n",
    "y_train = train_data.iloc[:, 0].values\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Reshape for CNN\n",
    "X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encoding for CNN\n",
    "y_train_cnn = to_categorical(y_train)\n",
    "y_test_cnn = to_categorical(y_test)\n",
    "\n",
    "print(\"Training models...\")\n",
    "\n",
    "# Train KNN\n",
    "print(\"Training KNN...\")\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "# Train SVM\n",
    "print(\"Training SVM...\")\n",
    "svm = SVC(C=1.0, kernel='linear')\n",
    "svm.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "# Train Decision Tree\n",
    "print(\"Training Decision Tree...\")\n",
    "decision_tree = DecisionTreeClassifier(max_depth=10)\n",
    "decision_tree.fit(X_train.reshape(len(X_train), -1), y_train)\n",
    "\n",
    "# Train CNN\n",
    "print(\"Training CNN...\")\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train_cnn, y_train_cnn, epochs=3, batch_size=128, validation_data=(X_test_cnn, y_test_cnn), verbose=1)\n",
    "\n",
    "# Store all models in a dictionary\n",
    "models = {\n",
    "    'knn': knn,\n",
    "    'svm': svm,\n",
    "    'log_reg': log_reg,\n",
    "    'decision_tree': decision_tree,\n",
    "    'cnn_model': cnn_model\n",
    "}\n",
    "\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec30e6a",
   "metadata": {},
   "source": [
    "## preprocessing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ee800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Preprocess the uploaded image to match the EMNIST format\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize to 28x28\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    \n",
    "    # Invert image (EMNIST digits are white on black)\n",
    "    image = 255 - image\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af5dfe",
   "metadata": {},
   "source": [
    "## predicting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d4d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit(image, models):\n",
    "    \"\"\"\n",
    "    Make predictions using all trained models\n",
    "    \"\"\"\n",
    "    # Prepare image for different model formats\n",
    "    img_flat = image.reshape(1, -1)\n",
    "    img_cnn = image.reshape(1, 28, 28, 1)\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    predictions['KNN'] = models['knn'].predict(img_flat)[0]\n",
    "    predictions['SVM'] = models['svm'].predict(img_flat)[0]\n",
    "    predictions['Logistic Regression'] = models['log_reg'].predict(img_flat)[0]\n",
    "    predictions['Decision Tree'] = models['decision_tree'].predict(img_flat)[0]\n",
    "    predictions['CNN'] = np.argmax(models['cnn_model'].predict(img_cnn), axis=1)[0]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df72b1",
   "metadata": {},
   "source": [
    "## Plotting result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067e097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_results(image, predictions):\n",
    "    \"\"\"\n",
    "    Display the image and predictions from all models\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.subplot(1, 2, 2)\n",
    "    models = list(predictions.keys())\n",
    "    preds = list(predictions.values())\n",
    "    \n",
    "    # Create a table with predictions\n",
    "    cell_text = [[model, str(pred)] for model, pred in predictions.items()]\n",
    "    plt.table(cellText=cell_text, \n",
    "             colLabels=['Model', 'Prediction'],\n",
    "             loc='center',\n",
    "             cellLoc='center')\n",
    "    plt.axis('off')\n",
    "    plt.title('Model Predictions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba193925",
   "metadata": {},
   "source": [
    "## uploading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_upload(change):\n",
    "    \"\"\"\n",
    "    Handle the file upload and make predictions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the uploaded file's content\n",
    "        content = change.new[0].content\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        image = plt.imread(io.BytesIO(content))\n",
    "        \n",
    "        # Preprocess image\n",
    "        processed_image = preprocess_image(image)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = predict_digit(processed_image, models)\n",
    "        \n",
    "        # Display results\n",
    "        plot_prediction_results(processed_image, predictions)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52b5be",
   "metadata": {},
   "source": [
    "## displaying result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5844b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file upload widget\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='image/*',  # Accept only image files\n",
    "    multiple=False,    # Only single file upload\n",
    "    description='Upload Image'\n",
    ")\n",
    "\n",
    "# Register the callback\n",
    "upload_widget.observe(handle_upload, names='value')\n",
    "\n",
    "# Display the widget\n",
    "display(upload_widget)\n",
    "\n",
    "print(\"Upload an image of a handwritten digit to get predictions from all models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41990a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
